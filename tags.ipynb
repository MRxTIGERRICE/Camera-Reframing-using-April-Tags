{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4daf0f23",
   "metadata": {},
   "source": [
    "# Pre-Requisites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32f4f3b",
   "metadata": {},
   "source": [
    "Download **A4 - 20mm squares - 13x9 verticies, 14x10 squares** variant from https://markhedleyjones.com/projects/calibration-checkerboard-collection and print it to take several photos of it from the IP camera on the line where the checker board is clearly visible at different angles and orientations as possible. Check the reference ZIP file which contains the checkerboard images here which i have taken for testing it at the office"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20768edd",
   "metadata": {},
   "source": [
    "Zip File link:https://drive.google.com/file/d/1CijilFYJrcAxvWLI7jY-4R5tW8J3Kmld/view?usp=sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1b5b5b",
   "metadata": {},
   "source": [
    "after taking photos as described, create a folder named calib and paste all the photos into it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618a5c63",
   "metadata": {},
   "source": [
    "visit   https://shiqiliu-67.github.io/apriltag-generator/\n",
    "for downloading the apriltags, stick them physically onto the background where the camera needs to be calibrated to."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4f88f1",
   "metadata": {},
   "source": [
    "please install the following dependencies first:\n",
    "- pupil_apriltags\n",
    "- yaml\n",
    "- cv2\n",
    "- pickle\n",
    "- numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e248d582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: pupil_apriltags in d:\\eternal robotics\\er\\lib\\site-packages (1.0.4.post11)\n",
      "Requirement already satisfied: opencv-python in d:\\eternal robotics\\er\\lib\\site-packages (4.10.0.84)\n",
      "Requirement already satisfied: numpy in d:\\eternal robotics\\er\\lib\\site-packages (from pupil_apriltags) (1.26.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pupil_apriltags opencv-python pyyaml numpy pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf13716",
   "metadata": {},
   "source": [
    "# Code for saving camera intrinsics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2e43537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Found 13 calibration images.\n",
      "[INFO] Calibration successful.\n",
      "Camera matrix:\n",
      " [[1.23905339e+03 0.00000000e+00 9.85581262e+02]\n",
      " [0.00000000e+00 1.24885756e+03 5.28625307e+02]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00]]\n",
      "Distortion coefficients:\n",
      " [[-0.33954079  0.12188955  0.0033804  -0.00256683  0.00663979]]\n",
      "[INFO] Saved to camera_intrinsics.pkl\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "def generate_camera_intrinsics(\n",
    "    calib_folder=\"calib\", \n",
    "    pattern_size=(13, 9),       # 13 x 9 inner corners\n",
    "    square_size=0.02            # 20mm squares in meters\n",
    "):\n",
    "    objp = np.zeros((pattern_size[0]*pattern_size[1], 3), np.float32)\n",
    "    objp[:, :2] = np.mgrid[0:pattern_size[0], 0:pattern_size[1]].T.reshape(-1, 2)\n",
    "    objp *= square_size\n",
    "\n",
    "    objpoints = []  # 3D points in real-world space\n",
    "    imgpoints = []  # 2D points in image plane\n",
    "\n",
    "    images = glob.glob(os.path.join(calib_folder, '*.jpg'))\n",
    "\n",
    "    if not images:\n",
    "        raise RuntimeError(f\"No images found in {calib_folder}\")\n",
    "\n",
    "    print(f\"[INFO] Found {len(images)} calibration images.\")\n",
    "\n",
    "    for fname in images:\n",
    "        img = cv2.imread(fname)\n",
    "        if img is None:\n",
    "            print(f\"[WARNING] Could not read image: {fname}\")\n",
    "            continue\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        ret, corners = cv2.findChessboardCorners(gray, pattern_size, None)\n",
    "\n",
    "        if ret:\n",
    "            objpoints.append(objp)\n",
    "            corners2 = cv2.cornerSubPix(\n",
    "                gray, corners, (11, 11), (-1, -1),\n",
    "                criteria=(cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "            )\n",
    "            imgpoints.append(corners2)\n",
    "\n",
    "            # Optional: show visual feedback\n",
    "            vis = img.copy()\n",
    "            cv2.drawChessboardCorners(vis, pattern_size, corners2, ret)\n",
    "            cv2.imshow('Detected Corners', vis)\n",
    "            cv2.waitKey(100)\n",
    "        else:\n",
    "            print(f\"[WARNING] Corners not found in: {fname}\")\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    if len(objpoints) < 5:\n",
    "        raise RuntimeError(\"Not enough valid calibration images with detected corners.\")\n",
    "\n",
    "    # Calibrate\n",
    "    ret, K, dist, rvecs, tvecs = cv2.calibrateCamera(\n",
    "        objpoints, imgpoints, gray.shape[::-1], None, None\n",
    "    )\n",
    "\n",
    "    print(\"[INFO] Calibration successful.\")\n",
    "    print(\"Camera matrix:\\n\", K)\n",
    "    print(\"Distortion coefficients:\\n\", dist)\n",
    "\n",
    "    # Save calibration data\n",
    "    with open(\"camera_intrinsics.pkl\", \"wb\") as f:\n",
    "        pickle.dump({'K': K, 'dist': dist}, f)\n",
    "\n",
    "    print(\"[INFO] Saved to camera_intrinsics.pkl\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    generate_camera_intrinsics(\"calib\", pattern_size=(13, 9), square_size=0.02)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbd6709",
   "metadata": {},
   "source": [
    "# 1. Code for saving Coords(Single-Threaded)\n",
    "(Multi-Threaded available at 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348a07c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import yaml\n",
    "from pupil_apriltags import Detector\n",
    "\n",
    "def save_reference_poses(rtsp_url, tag_size=0.04):\n",
    "    cap = cv2.VideoCapture(rtsp_url)\n",
    "    if not cap.isOpened():\n",
    "        print(\"[ERROR] Cannot open RTSP stream.\")\n",
    "        return\n",
    "\n",
    "    with open(\"camera_intrinsics.pkl\", \"rb\") as f:\n",
    "        data = pickle.load(f)\n",
    "    K = data['K']\n",
    "    dist = data['dist']\n",
    "\n",
    "    fx, fy = K[0, 0], K[1, 1]\n",
    "    cx, cy = K[0, 2], K[1, 2]\n",
    "    camera_params = [fx, fy, cx, cy]\n",
    "\n",
    "    detector = Detector(families='tag36h11')\n",
    "\n",
    "    reference_data = {}\n",
    "\n",
    "    print(\"[INFO] Press 's' to save the current tag pose. Press 'q' to quit.\")\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            continue\n",
    "\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        detections = detector.detect(\n",
    "            gray,\n",
    "            estimate_tag_pose=True,\n",
    "            camera_params=camera_params,\n",
    "            tag_size=tag_size\n",
    "        )\n",
    "\n",
    "        for det in detections:\n",
    "            rvec, _ = cv2.Rodrigues(det.pose_R)\n",
    "            tvec = det.pose_t\n",
    "            tag_id = det.tag_id\n",
    "\n",
    "            cv2.drawFrameAxes(frame, K, dist, rvec, tvec, tag_size / 2)\n",
    "            cv2.putText(frame, f\"ID {tag_id}\", tuple(det.center.astype(int)), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "\n",
    "        cv2.imshow(\"Save Reference Pose\", frame)\n",
    "        key = cv2.waitKey(1)\n",
    "\n",
    "        if key == ord('s'):\n",
    "            for det in detections:\n",
    "                rvec, _ = cv2.Rodrigues(det.pose_R)\n",
    "                tvec = det.pose_t\n",
    "                reference_data[det.tag_id] = {\n",
    "                    'rvec': rvec.ravel().tolist(),\n",
    "                    'tvec': tvec.ravel().tolist()\n",
    "                }\n",
    "            cv2.imwrite(\"reference_snapshot.jpg\", frame)\n",
    "            with open(\"reference_pose.yaml\", \"w\") as f:\n",
    "                yaml.dump(reference_data, f)\n",
    "            print(\"[INFO] Reference pose and snapshot saved.\")\n",
    "            print(\"[INFO] Saved pose for detected tags.\")\n",
    "        \n",
    "        elif key == ord('q'):\n",
    "            with open(\"reference_pose.yaml\", \"w\") as f:\n",
    "                yaml.dump(reference_data, f, sort_keys=True)\n",
    "            print(\"[INFO] Reference poses saved to reference_pose.yaml\")\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    rtsp_url = \"rtsp://your_rtsp_stream\"\n",
    "    save_reference_poses(rtsp_url)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84d2115",
   "metadata": {},
   "source": [
    "# 2. Code for Recalibration(Multi-Threaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9639cd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pickle\n",
    "import yaml\n",
    "from pupil_apriltags import Detector\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import yaml\n",
    "import threading\n",
    "import pickle\n",
    "from pupil_apriltags import Detector\n",
    "\n",
    "class VideoCaptureAsync:\n",
    "    def __init__(self, src=0):\n",
    "        self.src = src\n",
    "        self.cap = cv2.VideoCapture(self.src)\n",
    "        self.grabbed, self.frame = self.cap.read()\n",
    "        self.started = False\n",
    "        self.read_lock = threading.Lock()\n",
    "\n",
    "    def start(self):\n",
    "        if self.started:\n",
    "            print('[WARNING] Video capture already started.')\n",
    "            return None\n",
    "        self.started = True\n",
    "        self.thread = threading.Thread(target=self.update, daemon=True)\n",
    "        self.thread.start()\n",
    "        return self\n",
    "\n",
    "    def update(self):\n",
    "        while self.started:\n",
    "            grabbed, frame = self.cap.read()\n",
    "            with self.read_lock:\n",
    "                self.grabbed = grabbed\n",
    "                self.frame = frame\n",
    "\n",
    "    def read(self):\n",
    "        with self.read_lock:\n",
    "            frame = self.frame.copy() if self.frame is not None else None\n",
    "            grabbed = self.grabbed\n",
    "        return grabbed, frame\n",
    "\n",
    "    def stop(self):\n",
    "        self.started = False\n",
    "        self.thread.join()\n",
    "        self.cap.release()\n",
    "\n",
    "# === Parameters ===\n",
    "RTSP_URL    = \"rtsp://your_rtsp_stream\"\n",
    "TAG_SIZE    = 0.04      # meters\n",
    "TOLERANCE_T = 0.01      # meters\n",
    "TOLERANCE_R = 5         # degrees\n",
    "FONT        = cv2.FONT_HERSHEY_SIMPLEX\n",
    "ARROW_THICKNESS = 4\n",
    "WIN_W, WIN_H = 1280, 720\n",
    "\n",
    "# === Load Camera Intrinsics ===\n",
    "with open(\"camera_intrinsics.pkl\", \"rb\") as f:\n",
    "    intr = pickle.load(f)\n",
    "K    = intr[\"K\"]\n",
    "dist = intr[\"dist\"]\n",
    "fx, fy = K[0,0], K[1,1]\n",
    "cx, cy = K[0,2], K[1,2]\n",
    "camera_params = [fx, fy, cx, cy]\n",
    "\n",
    "# === Load Reference Poses & Snapshot ===\n",
    "with open(\"reference_pose.yaml\", \"r\") as f:\n",
    "    reference_data = yaml.safe_load(f)\n",
    "reference_data = {int(k): v for k, v in reference_data.items()}\n",
    "\n",
    "snapshot = cv2.imread(\"reference_snapshot.jpg\")\n",
    "snapshot_resized = cv2.resize(snapshot, (WIN_W, WIN_H)) if snapshot is not None else None\n",
    "\n",
    "# === Init Camera & Tag Detector ===\n",
    "cap = VideoCaptureAsync(rtsp_url).start()\n",
    "\n",
    "detector = Detector(families=\"tag36h11\", nthreads=4)\n",
    "\n",
    "def draw_guides(frame, t_diff, r_diff):\n",
    "    h, w = frame.shape[:2]\n",
    "    cx_, cy_ = w // 2, h // 2\n",
    "\n",
    "    t_cm = np.round(t_diff * 100, 2)\n",
    "    r_deg = np.round(r_diff, 2)\n",
    "\n",
    "    guidance = []\n",
    "\n",
    "    # X-axis\n",
    "    if t_diff[0] > TOLERANCE_T:\n",
    "        cv2.arrowedLine(frame, (int(w*0.9), cy_), (int(w*0.8), cy_), (0,0,255), ARROW_THICKNESS)\n",
    "        guidance.append((\"Right\", t_cm[0]))\n",
    "    elif t_diff[0] < -TOLERANCE_T:\n",
    "        cv2.arrowedLine(frame, (int(w*0.1), cy_), (int(w*0.2), cy_), (0,0,255), ARROW_THICKNESS)\n",
    "        guidance.append((\"Left\", abs(t_cm[0])))\n",
    "\n",
    "    # Y-axis\n",
    "    if t_diff[1] > TOLERANCE_T:\n",
    "        cv2.arrowedLine(frame, (cx_, int(h*0.9)), (cx_, int(h*0.8)), (0,255,0), ARROW_THICKNESS)\n",
    "        guidance.append((\"Down\", t_cm[1]))\n",
    "    elif t_diff[1] < -TOLERANCE_T:\n",
    "        cv2.arrowedLine(frame, (cx_, int(h*0.1)), (cx_, int(h*0.2)), (0,255,0), ARROW_THICKNESS)\n",
    "        guidance.append((\"Up\", abs(t_cm[1])))\n",
    "\n",
    "    # Z-axis\n",
    "    if t_diff[2] > TOLERANCE_T:\n",
    "        guidance.append((\"Forward\", t_cm[2]))\n",
    "    elif t_diff[2] < -TOLERANCE_T:\n",
    "        guidance.append((\"Backward\", abs(t_cm[2])))\n",
    "\n",
    "    # display each on correct edge\n",
    "    for direction, offset in guidance:\n",
    "        text = f\"Move {direction} by {offset:.1f} cm\"\n",
    "        sz, _ = cv2.getTextSize(text, FONT, 0.6, 2)\n",
    "\n",
    "        if direction == \"Left\":\n",
    "            pos = (10, cy_)\n",
    "        elif direction == \"Right\":\n",
    "            pos = (w - sz[0] - 10, cy_)\n",
    "        elif direction == \"Up\":\n",
    "            pos = ((w - sz[0]) // 2, 30)\n",
    "        elif direction == \"Down\":\n",
    "            pos = ((w - sz[0]) // 2, h - 10)\n",
    "        elif direction == \"Forward\":\n",
    "            pos = ((w - sz[0]) // 2, cy_ - 40)\n",
    "        else:  # Backward\n",
    "            pos = ((w - sz[0]) // 2, cy_ + 40)\n",
    "\n",
    "        cv2.putText(frame, text, pos, FONT, 0.6, (0,255,255), 2)\n",
    "\n",
    "    # Rotation (top-left)\n",
    "    axis_names = [\"Yaw (Z)\", \"Pitch (Y)\", \"Roll (X)\"]\n",
    "    for i, angle in enumerate(r_deg):\n",
    "        if abs(angle) > TOLERANCE_R:\n",
    "            sign = \"↻\" if r_diff[i] > 0 else \"↺\"\n",
    "            txt = f\"Rotate {axis_names[i]} {sign} by {abs(angle):.1f}°\"\n",
    "            cv2.putText(frame, txt, (10, 30 + 30 * (i + 1)), FONT, 0.6, (0, 0, 255), 2)\n",
    "\n",
    "\n",
    "cv2.namedWindow(\"Recalibration\", cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow(\"Recalibration\", WIN_W, WIN_H)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    dets = detector.detect(gray, estimate_tag_pose=True, camera_params=camera_params, tag_size=TAG_SIZE)\n",
    "\n",
    "    for det in dets:\n",
    "        tid = det.tag_id\n",
    "        if tid not in reference_data:\n",
    "            continue\n",
    "\n",
    "        rvec_now, _ = cv2.Rodrigues(det.pose_R)\n",
    "        tvec_now = det.pose_t.ravel()\n",
    "        ref = reference_data[tid]\n",
    "        rvec_ref = np.array(ref[\"rvec\"])\n",
    "        tvec_ref = np.array(ref[\"tvec\"])\n",
    "\n",
    "        dR = cv2.Rodrigues(det.pose_R @ cv2.Rodrigues(rvec_ref)[0].T)[0].ravel()\n",
    "        r_diff = np.rad2deg(dR)\n",
    "        t_diff = tvec_now - tvec_ref\n",
    "\n",
    "        cv2.drawFrameAxes(frame, K, dist, rvec_now, tvec_now, TAG_SIZE / 2)\n",
    "        draw_guides(frame, t_diff, r_diff)\n",
    "\n",
    "    # Overlay reference image if within threshold\n",
    "    if dets and snapshot_resized is not None:\n",
    "        if (np.all(np.abs(t_diff) < 1.5 * TOLERANCE_T) and\n",
    "            np.all(np.abs(r_diff) < 1.5 * TOLERANCE_R)):\n",
    "            snapshot_overlay = cv2.resize(snapshot_resized, (frame.shape[1], frame.shape[0]))\n",
    "            frame = cv2.addWeighted(frame, 0.7, snapshot_overlay, 0.3, 0)\n",
    "\n",
    "    # Display main window\n",
    "    cv2.imshow(\"Recalibration\", cv2.resize(frame, (WIN_W, WIN_H)))\n",
    "\n",
    "    # Display separate reference snapshot\n",
    "    if snapshot_resized is not None:\n",
    "        cv2.imshow(\"Reference Snapshot\", snapshot_resized)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.stop()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc52a547",
   "metadata": {},
   "source": [
    "# 3.Multi-Threading approach for saving co-ords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f724074b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import yaml\n",
    "import threading\n",
    "import pickle\n",
    "from pupil_apriltags import Detector\n",
    "\n",
    "class VideoCaptureAsync:\n",
    "    def __init__(self, src=0):\n",
    "        self.src = src\n",
    "        self.cap = cv2.VideoCapture(self.src)\n",
    "        self.grabbed, self.frame = self.cap.read()\n",
    "        self.started = False\n",
    "        self.read_lock = threading.Lock()\n",
    "\n",
    "    def start(self):\n",
    "        if self.started:\n",
    "            print('[WARNING] Video capture already started.')\n",
    "            return None\n",
    "        self.started = True\n",
    "        self.thread = threading.Thread(target=self.update, daemon=True)\n",
    "        self.thread.start()\n",
    "        return self\n",
    "\n",
    "    def update(self):\n",
    "        while self.started:\n",
    "            grabbed, frame = self.cap.read()\n",
    "            with self.read_lock:\n",
    "                self.grabbed = grabbed\n",
    "                self.frame = frame\n",
    "\n",
    "    def read(self):\n",
    "        with self.read_lock:\n",
    "            frame = self.frame.copy() if self.frame is not None else None\n",
    "            grabbed = self.grabbed\n",
    "        return grabbed, frame\n",
    "\n",
    "    def stop(self):\n",
    "        self.started = False\n",
    "        self.thread.join()\n",
    "        self.cap.release()\n",
    "\n",
    "\n",
    "def save_reference_poses(rtsp_url, tag_size=0.04):\n",
    "    cap = VideoCaptureAsync(rtsp_url).start()\n",
    "    \n",
    "    with open(\"camera_intrinsics.pkl\", \"rb\") as f:\n",
    "        data = pickle.load(f)\n",
    "    K = data['K']\n",
    "    dist = data['dist']\n",
    "\n",
    "    fx, fy = K[0, 0], K[1, 1]\n",
    "    cx, cy = K[0, 2], K[1, 2]\n",
    "    camera_params = [fx, fy, cx, cy]\n",
    "\n",
    "    detector = Detector(families='tag36h11')\n",
    "\n",
    "    reference_data = {}\n",
    "\n",
    "    print(\"[INFO] Press 's' to save the current tag pose. Press 'q' to quit.\")\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret or frame is None:\n",
    "            continue\n",
    "\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        detections = detector.detect(\n",
    "            gray,\n",
    "            estimate_tag_pose=True,\n",
    "            camera_params=camera_params,\n",
    "            tag_size=tag_size\n",
    "        )\n",
    "\n",
    "        for det in detections:\n",
    "            rvec, _ = cv2.Rodrigues(det.pose_R)\n",
    "            tvec = det.pose_t\n",
    "            tag_id = det.tag_id\n",
    "\n",
    "            cv2.drawFrameAxes(frame, K, dist, rvec, tvec, tag_size / 2)\n",
    "            cv2.putText(frame, f\"ID {tag_id}\", tuple(det.center.astype(int)), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "\n",
    "        cv2.imshow(\"Save Reference Pose\", frame)\n",
    "        key = cv2.waitKey(1)\n",
    "\n",
    "        if key == ord('s'):\n",
    "            for det in detections:\n",
    "                rvec, _ = cv2.Rodrigues(det.pose_R)\n",
    "                tvec = det.pose_t\n",
    "                reference_data[det.tag_id] = {\n",
    "                    'rvec': rvec.ravel().tolist(),\n",
    "                    'tvec': tvec.ravel().tolist()\n",
    "                }\n",
    "            cv2.imwrite(\"reference_snapshot.jpg\", frame)\n",
    "            with open(\"reference_pose.yaml\", \"w\") as f:\n",
    "                yaml.dump(reference_data, f)\n",
    "            print(\"[INFO] Reference pose and snapshot saved.\")\n",
    "        \n",
    "        elif key == ord('q'):\n",
    "            with open(\"reference_pose.yaml\", \"w\") as f:\n",
    "                yaml.dump(reference_data, f, sort_keys=True)\n",
    "            print(\"[INFO] Reference poses saved to reference_pose.yaml\")\n",
    "            break\n",
    "\n",
    "    cap.stop()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    rtsp_url = \"rtsp://your_rtsp_stream\"\n",
    "    save_reference_poses(rtsp_url)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ER",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
